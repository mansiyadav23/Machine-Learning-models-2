{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "Apprentice Chef, Inc. is a meal kit company. They offer gourmet meals that are daily-prepared to your doorstep. \n",
    "\n",
    "A cross-selling promotion called Halfway There has been launched by Apprentice Chef in order to diversify their revenue stream. \n",
    "\n",
    "Customers who subscribe to Halfway There will receive a half bottle of wine from a local California vineyard every Wednesday.\n",
    "\n",
    "Apprentice Chef want to know which customers will subscribe to this service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansiyadav/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import numpy                   as np                         # mathematical essentials\n",
    "import pandas                  as pd                         # data science essentials\n",
    "import matplotlib.pyplot       as plt                        # essential graphical output\n",
    "import seaborn                 as sns                        # enhanced graphical output\n",
    "import statsmodels.formula.api as smf                        # regression modeling\n",
    "from sklearn.model_selection   import train_test_split       # train-test split\n",
    "from sklearn.linear_model      import LogisticRegression     # logistic regression\n",
    "from sklearn.metrics           import confusion_matrix       # confusion matrix\n",
    "from sklearn.metrics           import roc_auc_score          # auc score\n",
    "from sklearn.neighbors         import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors         import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing     import StandardScaler         # standard scaler\n",
    "from sklearn.tree              import DecisionTreeClassifier # classification trees\n",
    "from sklearn.tree              import export_graphviz        # exports graphics\n",
    "from sklearn.externals.six     import StringIO               # saves objects in memory\n",
    "from IPython.display           import Image                  # displays on frontend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "file = 'Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "# Read the file as original_df\n",
    "original_df = pd.read_excel(file)\n",
    "\n",
    "# coping the new dataset\n",
    "mydf = original_df\n",
    "\n",
    "# View the top 5 columns of the dataset\n",
    "#mydf.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlations with CROSS SELL SUCCESS\n",
    "#df_corr = mydf.corr().round(2)\n",
    "#df_corr.loc['CROSS_SELL_SUCCESS'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see what is the biggest factor in determining cross sell success. <br>\n",
    "\n",
    "Followed recommendations pct: Percentage of time customer followed the meal recommendation generated for them. <br>\n",
    "The more people follow recommendations the more likely they are to buy wine that we're trying to sell to them. (Cross sell success)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Splitting email address into <br>\n",
    "1. Personal\n",
    "2. Professional\n",
    "3. Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personal        861\n",
       "professional    696\n",
       "junk            389\n",
       "Name: DOMAIN_GRP, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create an empty list\n",
    "sep_email = [] \n",
    "\n",
    "# looping over each email address\n",
    "for index, col in mydf.iterrows(): \n",
    "    split_email = mydf.loc[index, 'EMAIL'].split(sep = '@') # splitting email domain at '@'\n",
    "    sep_email.append(split_email)                           # appending sep_email with the results\n",
    "    \n",
    "# converting sep_email into a DataFrame \n",
    "email_df = pd.DataFrame(sep_email)\n",
    "\n",
    "# Concatenating with original dataframe\n",
    "# Reading the original file again\n",
    "mydf = pd.read_excel('Apprentice_Chef_Dataset.xlsx')\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = ['NAME' , 'EMAIL_DOMAIN']\n",
    "\n",
    "# concatenating personal_email_domain with original DataFrame \n",
    "mydf = pd.concat([mydf, email_df.loc[:, 'EMAIL_DOMAIN']],\n",
    "                 axis = 1)\n",
    "\n",
    "# EMAIL DOMAIN types\n",
    "professional_email_domains = ['@mmm.com','@amex.com','@apple.com','@boeing.com','@caterpillar.com', \n",
    "                              '@chevron.com','@cisco.com','@cocacola.com','@disney.com','@dupont.com', \n",
    "                              '@exxon.com','@ge.org','@goldmansacs.com','@homedepot.com','@ibm.com',\n",
    "                              '@intel.com','@jnj.com','@jpmorgan.com','@mcdonalds.com','@merck.com', \n",
    "                              '@microsoft.com','@nike.com','@pfizer.com','@pg.com','@travelers.com', \n",
    "                              '@unitedtech.com','@unitedhealth.com','@verizon.com','@visa.com','@walmart.com']\n",
    "personal_email_domains     = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "junk_email_domains         = ['@me.com', '@aol.com', '@hotmail.com','@live.com', '@msn.com', '@passport.com']\n",
    "\n",
    "# create another new empty list\n",
    "new_lst = []  \n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in mydf['EMAIL_DOMAIN']:\n",
    "    if '@' + domain in professional_email_domains: \n",
    "        new_lst.append('professional')\n",
    "    elif '@' + domain in personal_email_domains:\n",
    "        new_lst.append('personal')\n",
    "    elif '@' + domain in junk_email_domains:\n",
    "        new_lst.append('junk')\n",
    "    else:\n",
    "        print('Unknown')\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "mydf['DOMAIN_GRP'] = pd.Series(new_lst)\n",
    "\n",
    "# checking results\n",
    "mydf['DOMAIN_GRP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding categorical variables\n",
    "one_hot_DOMAIN_GRP = pd.get_dummies(mydf['DOMAIN_GRP'])\n",
    "\n",
    "# Drop categorical variables after they've been encoded\n",
    "mydf = mydf.drop('DOMAIN_GRP', axis = 1)\n",
    "\n",
    "# Join codings together\n",
    "mydf = mydf.join([one_hot_DOMAIN_GRP])\n",
    "\n",
    "# Save new columns\n",
    "new_columns = mydf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flagging outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flagging outliers\n",
    "# setting outlier thresholds\n",
    "TOTAL_MEALS_ORDERED_hi         = 300 \n",
    "UNIQUE_MEALS_PURCH_hi          = 10\n",
    "CONTACTS_W_CUSTOMER_SERVICE_lo = 3  \n",
    "CONTACTS_W_CUSTOMER_SERVICE_hi = 12\n",
    "AVG_TIME_PER_SITE_VISIT_hi     = 200 \n",
    "CANCELLATIONS_BEFORE_NOON_hi   = 7    \n",
    "CANCELLATIONS_AFTER_NOON_hi    = 2\n",
    "WEEKLY_PLAN_hi                 = 15\n",
    "LATE_DELIVERIES_hi             = 10     \n",
    "AVG_PREP_VID_TIME_hi           = 300\n",
    "LARGEST_ORDER_SIZE_lo          = 1\n",
    "LARGEST_ORDER_SIZE_hi          = 10\n",
    "AVG_CLICKS_PER_VISIT_lo        = 8\n",
    "REVENUE_hi                     = 2500\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "## Feature Engineering (outlier thresholds)                                 ##\n",
    "##############################################################################\n",
    "\n",
    "# developing features (columns) for outliers\n",
    "\n",
    "# Total_meals_ordered\n",
    "mydf['OUT_TOTAL_MEALS_ORDERED'] = 0\n",
    "condition_hi = mydf.loc[0:,'OUT_TOTAL_MEALS_ORDERED'][mydf['TOTAL_MEALS_ORDERED'] > TOTAL_MEALS_ORDERED_hi]\n",
    "\n",
    "mydf['OUT_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,\n",
    "                                        value      = 1, \n",
    "                                        inplace    = True)\n",
    "\n",
    "# Unique_meals_ordered\n",
    "mydf['OUT_UNIQUE_MEALS_PURCH'] = 0\n",
    "condition_hi = mydf.loc[0:, 'OUT_UNIQUE_MEALS_PURCH'][mydf['UNIQUE_MEALS_PURCH'] > UNIQUE_MEALS_PURCH_hi] \n",
    "\n",
    "mydf['OUT_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_hi,\n",
    "                                       value      = 1,\n",
    "                                       inplace     = True)\n",
    "\n",
    "# Contacts_W_customer_service\n",
    "mydf['OUT_CONTACTS_W_CUSTOMER_SERVICE'] = 0\n",
    "condition_lo = mydf.loc[0:, 'OUT_CONTACTS_W_CUSTOMER_SERVICE'][mydf['CONTACTS_W_CUSTOMER_SERVICE'] < CONTACTS_W_CUSTOMER_SERVICE_lo] \n",
    "\n",
    "mydf['OUT_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_lo,\n",
    "                                       value      = 1,\n",
    "                                       inplace    = True)\n",
    "\n",
    "# contacts_w_customer_service\n",
    "mydf['OUT_CONTACTS_W_CUSTOMER_SERVICE'] = 0\n",
    "condition_hi = mydf.loc[0:,'OUT_CONTACTS_W_CUSTOMER_SERVICE'][mydf['CONTACTS_W_CUSTOMER_SERVICE'] > CONTACTS_W_CUSTOMER_SERVICE_hi]\n",
    "\n",
    "mydf['OUT_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                                value      = 1, \n",
    "                                                inplace    = True)\n",
    "\n",
    "\n",
    "# avg_time_per_site_visit\n",
    "mydf['OUT_AVG_TIME_PER_SITE_VISIT'] = 0\n",
    "condition_hi = mydf.loc[0:,'OUT_AVG_TIME_PER_SITE_VISIT'][mydf['AVG_TIME_PER_SITE_VISIT'] > AVG_TIME_PER_SITE_VISIT_hi]\n",
    "\n",
    "mydf['OUT_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,\n",
    "                                            value      = 1, \n",
    "                                            inplace    = True)\n",
    "\n",
    "\n",
    "# cancellations_before_noon\n",
    "mydf['OUT_CANCELLATIONS_BEFORE_NOON'] = 0\n",
    "condition_hi = mydf.loc[0:,'OUT_CANCELLATIONS_BEFORE_NOON'][mydf['CANCELLATIONS_BEFORE_NOON'] > CANCELLATIONS_BEFORE_NOON_hi]\n",
    "\n",
    "mydf['OUT_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,\n",
    "                                              value      = 1, \n",
    "                                              inplace    = True)\n",
    "\n",
    "\n",
    "# cancellations_after_noon\n",
    "mydf['OUT_CANCELLATIONS_AFTER_NOON'] = 0\n",
    "condition_hi = mydf.loc[0:,'OUT_CANCELLATIONS_AFTER_NOON'][mydf['CANCELLATIONS_AFTER_NOON'] > CANCELLATIONS_AFTER_NOON_hi]\n",
    "\n",
    "mydf['OUT_CANCELLATIONS_AFTER_NOON'].replace(to_replace = condition_hi,\n",
    "                                             value      = 1, \n",
    "                                             inplace    = True)\n",
    "\n",
    "\n",
    "# weekly_plan\n",
    "mydf['OUT_WEEKLY_PLAN'] = 0\n",
    "condition_hi = mydf.loc[0:,'OUT_WEEKLY_PLAN'][mydf['WEEKLY_PLAN'] > WEEKLY_PLAN_hi]\n",
    "\n",
    "mydf['OUT_WEEKLY_PLAN'].replace(to_replace = condition_hi,\n",
    "                                value      = 1, \n",
    "                                inplace    = True)\n",
    "\n",
    "# late_deliveries\n",
    "mydf['OUT_LATE_DELIVERIES'] = 0\n",
    "condition_hi = mydf.loc[0:,'OUT_LATE_DELIVERIES'][mydf['LATE_DELIVERIES'] > LATE_DELIVERIES_hi]\n",
    "\n",
    "mydf['OUT_LATE_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1, \n",
    "                                    inplace    = True)\n",
    "\n",
    "# avg_prep_vid_time\n",
    "mydf['OUT_AVG_PREP_VID_TIME'] = 0\n",
    "condition_hi = mydf.loc[0:,'OUT_AVG_PREP_VID_TIME'][mydf['AVG_PREP_VID_TIME'] > AVG_PREP_VID_TIME_hi]\n",
    "\n",
    "mydf['OUT_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,\n",
    "                                      value      = 1, \n",
    "                                      inplace    = True)\n",
    "\n",
    "\n",
    "# largest_order_size\n",
    "mydf['OUT_LARGEST_ORDER_SIZE'] = 0\n",
    "condition_hi = mydf.loc[0:,'OUT_LARGEST_ORDER_SIZE'][mydf['LARGEST_ORDER_SIZE'] > LARGEST_ORDER_SIZE_hi]\n",
    "condition_lo = mydf.loc[0:,'OUT_LARGEST_ORDER_SIZE'][mydf['LARGEST_ORDER_SIZE'] < LARGEST_ORDER_SIZE_lo]\n",
    "mydf['OUT_LARGEST_ORDER_SIZE'].replace(to_replace = condition_lo,\n",
    "                                       value      = 1, \n",
    "                                       inplace    = True)\n",
    "mydf['OUT_LARGEST_ORDER_SIZE'].replace(to_replace = condition_hi,\n",
    "                                       value      = 1, \n",
    "                                       inplace    = True)\n",
    "\n",
    "\n",
    "# avg_clicks_per_visit\n",
    "mydf['OUT_AVG_CLICKS_PER_VISIT'] = 0\n",
    "condition_lo = mydf.loc[0:,'OUT_AVG_CLICKS_PER_VISIT'][mydf['AVG_CLICKS_PER_VISIT'] < AVG_CLICKS_PER_VISIT_lo]\n",
    "\n",
    "mydf['OUT_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_lo,\n",
    "                                         value      = 1, \n",
    "                                         inplace    = True)\n",
    "\n",
    "\n",
    "# revenue\n",
    "mydf['out_REVENUE'] = 0\n",
    "condition_hi = mydf.loc[0:,'out_REVENUE'][mydf['REVENUE'] > REVENUE_hi]\n",
    "\n",
    "mydf['out_REVENUE'].replace(to_replace = condition_hi,\n",
    "                            value      = 1,\n",
    "                            inplace    = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanatory Variables\n",
    "mydf_data = mydf.drop(['CROSS_SELL_SUCCESS','NAME' , 'EMAIL_DOMAIN','EMAIL','FIRST_NAME', 'FAMILY_NAME'], axis=1)\n",
    "\n",
    "# Response Variable\n",
    "mydf_target = mydf.loc[:, 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "#for val in mydf_data:\n",
    "#    print(f\"{val} +\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.452628\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>CROSS_SELL_SUCCESS</td> <th>  No. Observations:  </th>   <td>  1946</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>   <td>  1934</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>   <td>    11</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 15 Mar 2020</td>  <th>  Pseudo R-squ.:     </th>   <td>0.2790</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:51:08</td>      <th>  Log-Likelihood:    </th>  <td> -880.81</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th>  <td> -1221.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>4.800e-139</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                    <td>   -3.2552</td> <td>    0.625</td> <td>   -5.211</td> <td> 0.000</td> <td>   -4.479</td> <td>   -2.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_NUMBER</th>                <td>    0.7259</td> <td>    0.174</td> <td>    4.182</td> <td> 0.000</td> <td>    0.386</td> <td>    1.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON</th>    <td>    0.2518</td> <td>    0.043</td> <td>    5.865</td> <td> 0.000</td> <td>    0.168</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_AFTER_NOON</th>     <td>   -0.2893</td> <td>    0.132</td> <td>   -2.197</td> <td> 0.028</td> <td>   -0.547</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TASTES_AND_PREFERENCES</th>       <td>    0.4552</td> <td>    0.128</td> <td>    3.560</td> <td> 0.000</td> <td>    0.205</td> <td>    0.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_LOGINS</th>                    <td>    0.2243</td> <td>    0.101</td> <td>    2.214</td> <td> 0.027</td> <td>    0.026</td> <td>    0.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_LOGINS</th>                <td>   -0.2960</td> <td>    0.111</td> <td>   -2.667</td> <td> 0.008</td> <td>   -0.514</td> <td>   -0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REFRIGERATED_LOCKER</th>          <td>    0.5065</td> <td>    0.200</td> <td>    2.535</td> <td> 0.011</td> <td>    0.115</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FOLLOWED_RECOMMENDATIONS_PCT</th> <td>    0.0571</td> <td>    0.003</td> <td>   16.961</td> <td> 0.000</td> <td>    0.050</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>professional</th>                 <td>    1.0790</td> <td>    0.131</td> <td>    8.238</td> <td> 0.000</td> <td>    0.822</td> <td>    1.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OUT_UNIQUE_MEALS_PURCH</th>       <td>   -1.1385</td> <td>    0.558</td> <td>   -2.040</td> <td> 0.041</td> <td>   -2.232</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OUT_AVG_PREP_VID_TIME</th>        <td>    1.5391</td> <td>    0.701</td> <td>    2.197</td> <td> 0.028</td> <td>    0.166</td> <td>    2.912</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     CROSS_SELL_SUCCESS   No. Observations:                 1946\n",
       "Model:                          Logit   Df Residuals:                     1934\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Sun, 15 Mar 2020   Pseudo R-squ.:                  0.2790\n",
       "Time:                        19:51:08   Log-Likelihood:                -880.81\n",
       "converged:                       True   LL-Null:                       -1221.6\n",
       "Covariance Type:            nonrobust   LLR p-value:                4.800e-139\n",
       "================================================================================================\n",
       "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "Intercept                       -3.2552      0.625     -5.211      0.000      -4.479      -2.031\n",
       "MOBILE_NUMBER                    0.7259      0.174      4.182      0.000       0.386       1.066\n",
       "CANCELLATIONS_BEFORE_NOON        0.2518      0.043      5.865      0.000       0.168       0.336\n",
       "CANCELLATIONS_AFTER_NOON        -0.2893      0.132     -2.197      0.028      -0.547      -0.031\n",
       "TASTES_AND_PREFERENCES           0.4552      0.128      3.560      0.000       0.205       0.706\n",
       "PC_LOGINS                        0.2243      0.101      2.214      0.027       0.026       0.423\n",
       "MOBILE_LOGINS                   -0.2960      0.111     -2.667      0.008      -0.514      -0.078\n",
       "REFRIGERATED_LOCKER              0.5065      0.200      2.535      0.011       0.115       0.898\n",
       "FOLLOWED_RECOMMENDATIONS_PCT     0.0571      0.003     16.961      0.000       0.050       0.064\n",
       "professional                     1.0790      0.131      8.238      0.000       0.822       1.336\n",
       "OUT_UNIQUE_MEALS_PURCH          -1.1385      0.558     -2.040      0.041      -2.232      -0.045\n",
       "OUT_AVG_PREP_VID_TIME            1.5391      0.701      2.197      0.028       0.166       2.912\n",
       "================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logit_sig = smf.logit(formula = \"\"\" CROSS_SELL_SUCCESS ~  MOBILE_NUMBER +\n",
    "                                                            CANCELLATIONS_BEFORE_NOON +\n",
    "                                                            CANCELLATIONS_AFTER_NOON +\n",
    "                                                            TASTES_AND_PREFERENCES +\n",
    "                                                            PC_LOGINS +\n",
    "                                                            MOBILE_LOGINS +\n",
    "                                                            REFRIGERATED_LOCKER +\n",
    "                                                            FOLLOWED_RECOMMENDATIONS_PCT +\n",
    "                                                            professional +\n",
    "                                                            OUT_UNIQUE_MEALS_PURCH +\n",
    "                                                            OUT_AVG_PREP_VID_TIME \"\"\",\n",
    "                                     data    = mydf)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "logit_sig = logit_sig.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "logit_sig.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the significant variables in our logistic regression model. \n",
    "\n",
    "We will now use these significant variables to train and test our data to build different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prep:\n",
    "Train<br>\n",
    "Test<br>\n",
    "Split<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring the x variables\n",
    "x_variables = ['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON',\n",
    "               'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES',\n",
    "               'PC_LOGINS', 'MOBILE_LOGINS', 'REFRIGERATED_LOCKER',\n",
    "               'FOLLOWED_RECOMMENDATIONS_PCT', 'professional',\n",
    "               'OUT_UNIQUE_MEALS_PURCH', 'OUT_AVG_PREP_VID_TIME']\n",
    "\n",
    "# train/test split with the full model\n",
    "mydf_data   =  mydf.loc[ : , x_variables]\n",
    "mydf_target =  mydf.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            mydf_data,\n",
    "            mydf_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 222,\n",
    "            stratify     = mydf_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists for training set accuracy and test set accuracy\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "\n",
    "# build a visualization \n",
    "neighbors_settings = range(1, 18)\n",
    "\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    clf = KNeighborsClassifier(n_neighbors = n_neighbors) # building the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    training_accuracy.append(clf.score(X_train, y_train)) # recording the training set accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))       # recording the generalization accuracy\n",
    "\n",
    "\n",
    "# plot the visualization\n",
    "#fig, ax = plt.subplots(figsize=(12,8))\n",
    "#plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "#plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "#plt.ylabel(\"Accuracy\")\n",
    "#plt.xlabel(\"n_neighbors\")\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "# find the optimal number of neighbors\n",
    "opt_neighbors = test_accuracy.index(max(test_accuracy)) + 1\n",
    "#print(f\"\"\"The optimal number of neighbors is {opt_neighbors}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the data\n",
    "scaler.fit(mydf_data)\n",
    "\n",
    "# Transforming the data\n",
    "X_scaled     = scaler.transform(mydf_data)\n",
    "\n",
    "# converting to a DataFrame\n",
    "X_scaled_df  = pd.DataFrame(X_scaled) \n",
    "\n",
    "# train-test split with the scaled data\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            X_scaled_df,\n",
    "            mydf_target,\n",
    "            random_state = 222,\n",
    "            test_size = 0.25,\n",
    "            stratify = mydf_target)\n",
    "\n",
    "# Instantiating a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# Fitting the training data\n",
    "knn_fit = knn_opt.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set\n",
    "knn_pred = knn_fit.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Scoring the results\n",
    "#print('Training ACCURACY:', knn_fit.score(X_train_scaled, y_train_scaled).round(4))\n",
    "#print('Testing  ACCURACY:', knn_fit.score(X_test_scaled, y_test_scaled).round(4))\n",
    "#print('AUC Score        :', roc_auc_score(y_true  = y_test_scaled,\n",
    "#                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# creating an empty list for the results of all models\n",
    "model_performance = [['Model', 'Training Accuracy',\n",
    "                      'Testing Accuracy', 'AUC Value']]\n",
    "# Train accuracy\n",
    "knn_train_acc = knn_fit.score(X_train_scaled, y_train_scaled).round(4)\n",
    "\n",
    "\n",
    "# Test accuracy\n",
    "knn_test_acc  = knn_fit.score(X_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# auc value\n",
    "knn_auc       = roc_auc_score(y_true  = y_test_scaled,\n",
    "                              y_score = knn_pred).round(4)\n",
    "\n",
    "\n",
    "# Saving the results\n",
    "model_performance.append(['KNN Classification',\n",
    "                          knn_train_acc,\n",
    "                          knn_test_acc,\n",
    "                          knn_auc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 \n",
    "Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mansiyadav/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Instantiating a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 567)\n",
    "\n",
    "\n",
    "# Fitting the training data\n",
    "logreg_fit = logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set\n",
    "logreg_pred = logreg_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Scoring the results\n",
    "#print('Training ACCURACY:', logreg_fit.score(X_train, y_train).round(4))\n",
    "#print('Testing  ACCURACY:', logreg_fit.score(X_test, y_test).round(4))\n",
    "#print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "#                                          y_score = logreg_pred).round(4))\n",
    "\n",
    "# train accuracy\n",
    "logreg_train_acc  = logreg_fit.score(X_train, y_train).round(4)\n",
    "\n",
    "# test accuracy\n",
    "logreg_test_acc   = logreg_fit.score(X_test, y_test).round(4)\n",
    "\n",
    "# auc value\n",
    "logreg_auc = roc_auc_score(y_true  = y_test,\n",
    "                           y_score = logreg_pred).round(4)\n",
    "\n",
    "# saving the results\n",
    "model_performance.append(['Logistic Regression',\n",
    "                          logreg_train_acc,\n",
    "                          logreg_test_acc,\n",
    "                          logreg_auc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3\n",
    "Full Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# Fitting the training data\n",
    "full_tree_fit = full_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting on new data\n",
    "full_tree_pred = full_tree_fit.predict(X_test)\n",
    "\n",
    "# Scoring the model \n",
    "#print('Training ACCURACY:', full_tree_fit.score(X_train, y_train).round(4))\n",
    "#print('Testing  ACCURACY:', full_tree_fit.score(X_test, y_test).round(4))\n",
    "#print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "#                                          y_score = full_tree_pred).round(4))\n",
    "\n",
    "# Train accuracy\n",
    "full_tree_train_acc = full_tree_fit.score(X_train, y_train).round(4)\n",
    "\n",
    "# Test accuracy\n",
    "full_tree_test_acc  = full_tree_fit.score(X_test, y_test).round(4)\n",
    "\n",
    "# auc value\n",
    "full_tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                    y_score = full_tree_pred).round(4)\n",
    "\n",
    "# Saving the results\n",
    "model_performance.append(['Full Tree',\n",
    "                          full_tree_train_acc,\n",
    "                          full_tree_test_acc,\n",
    "                          full_tree_auc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4\n",
    "Pruned Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiaing a classification tree object\n",
    "tree_pruned      = DecisionTreeClassifier(max_depth = 4,\n",
    "                                          min_samples_leaf = 25,\n",
    "                                          random_state = 222)\n",
    "\n",
    "\n",
    "# Fitting the training data\n",
    "tree_pruned_fit  = tree_pruned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting on new data\n",
    "tree_pred = tree_pruned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# Scoring the model\n",
    "#print('Training ACCURACY:', tree_pruned_fit.score(X_train, y_train).round(4))\n",
    "#print('Testing  ACCURACY:', tree_pruned_fit.score(X_test, y_test).round(4))\n",
    "#print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "#                                          y_score = tree_pred).round(4))\n",
    "\n",
    "# Train accuracy\n",
    "p_tree_train_acc = tree_pruned_fit.score(X_train, y_train).round(4)\n",
    "\n",
    "\n",
    "# Test accuracy\n",
    "p_tree_test_acc  = tree_pruned_fit.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# auc value\n",
    "p_tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = tree_pred).round(4)\n",
    "\n",
    "# Saving the results\n",
    "model_performance.append(['Pruned Tree',\n",
    "                          p_tree_train_acc,\n",
    "                          p_tree_test_acc,\n",
    "                          p_tree_auc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>AUC Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Classification</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.7659</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7498</td>\n",
       "      <td>0.7474</td>\n",
       "      <td>0.7108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.7207</td>\n",
       "      <td>0.7064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.7947</td>\n",
       "      <td>0.7574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy  Testing Accuracy  AUC Value\n",
       "0   KNN Classification             0.7964            0.7659     0.7600\n",
       "1  Logistic Regression             0.7498            0.7474     0.7108\n",
       "2            Full Tree             0.9136            0.7207     0.7064\n",
       "3          Pruned Tree             0.8095            0.7947     0.7574"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to DataFrame and checking the results\n",
    "pd.DataFrame(model_performance[1:], columns = model_performance[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a DataFrame object\n",
    "model_performance_df = pd.DataFrame(model_performance[1:], columns = model_performance[0])\n",
    "\n",
    "\n",
    "# saving the DataFrame to Excel\n",
    "model_performance_df.to_excel('Classification Model Performance.xlsx',\n",
    "                              index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
